{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:37:28.010146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-02 17:37:28.184282: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-02 17:37:28.190409: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-02 17:37:28.190457: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-02 17:37:28.223712: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-02 17:37:29.032326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-02 17:37:29.032384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-02 17:37:29.032391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "DATA_PATH = \"../data/derived_data/items_with_floor/\"\n",
    "OUTPUT_PATH = \"../data/derived_data/data_augmented/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    # Vertical and Horizontal coordinate of the top-left corner of the bounding box in image. \n",
    "    offset_height, offset_width = random.randint(0, image.shape[0]//2 - 100), random.randint(0, image.shape[1]//2 - 50)\n",
    "    # Height and Width of the bounding box. \n",
    "    target_height, target_width = random.randint(image.shape[0]//2.5, image.shape[0] - offset_height), random.randint(image.shape[1]//2.5, image.shape[1] - offset_width)\n",
    "\n",
    "    return tf.image.crop_to_bounding_box(image, offset_height, offset_width, target_height, target_width)\n",
    "\n",
    "operations = [\n",
    "    tf.keras.layers.RandomRotation(0.2, interpolation=\"nearest\", seed=None),\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None),\n",
    "    random_crop,\n",
    "    tf.keras.layers.RandomHeight(0.25, interpolation='nearest', seed=None),\n",
    "    tf.keras.layers.RandomWidth(0.25, interpolation='nearest', seed=None),\n",
    "    tf.keras.layers.RandomContrast(0.25, seed=None),\n",
    "    tf.keras.layers.RandomBrightness(0.5, value_range=(50, 200), seed=None),\n",
    "    lambda image: tf.image.random_hue(image, 0.25, seed=None),\n",
    "    lambda image: tf.image.random_saturation(image, 0, 1, seed=None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:37:30.514893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-02 17:37:30.514940: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-02 17:37:30.514978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mizunno-laptop): /proc/driver/nvidia/version does not exist\n",
      "2023-08-02 17:37:30.515484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "N_RANDOM_OPERATIONS_COMBINATIONS = 100\n",
    "MAX_OPERATIONS_COMBINED = 4\n",
    "SAVE_IMAGE = True\n",
    "IMG_SIZE = 128\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE, interpolation=\"nearest\"),\n",
    "  tf.keras.layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "def no_agumentation(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img_arr = np.array(img)\n",
    "    img_filename = img_path.split(\"/\")[-1][:-4]\n",
    "    os.makedirs(f\"{OUTPUT_PATH}/{img_filename}\", exist_ok=True)\n",
    "    Image.fromarray(img_arr.astype(np.uint8), \"RGB\").save(f\"{OUTPUT_PATH}/{img_filename}/{img_filename}_{str(i)}.png\")\n",
    "\n",
    "def augment_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img_arr = np.array(img)\n",
    "\n",
    "    # without extension\n",
    "    img_filename = img_path.split(\"/\")[-1][:-4]\n",
    "\n",
    "    for i, op in enumerate(operations):\n",
    "        img_arr_augmented = op(img_arr)\n",
    "\n",
    "        if SAVE_IMAGE:\n",
    "            os.makedirs(f\"{OUTPUT_PATH}/{img_filename}\", exist_ok=True)\n",
    "            Image.fromarray(img_arr_augmented.numpy().astype(np.uint8), \"RGB\").save(f\"{OUTPUT_PATH}/{img_filename}/{img_filename}_{str(i)}.png\")\n",
    "\n",
    "        # img_arr_augmented = resize_and_rescale(img_arr_augmented)\n",
    "        # np.save(f\"{OUTPUT_PATH}/{img_filename}_{str(i)}\", img_arr_augmented.numpy().astype(np.float16))\n",
    "\n",
    "    random_ops_combs = [random.sample(operations, k=random.randint(1,MAX_OPERATIONS_COMBINED)) for _ in range(N_RANDOM_OPERATIONS_COMBINATIONS)]\n",
    "\n",
    "    for i, random_ops in enumerate(random_ops_combs, start=i+1):\n",
    "        img_arr_augmented = img_arr\n",
    "        for op in random_ops:\n",
    "            img_arr_augmented = op(img_arr_augmented)\n",
    "        \n",
    "        if SAVE_IMAGE:\n",
    "            os.makedirs(f\"{OUTPUT_PATH}/{img_filename}\", exist_ok=True)\n",
    "            Image.fromarray(img_arr_augmented.numpy().astype(np.uint8), \"RGB\").save(f\"{OUTPUT_PATH}/{img_filename}/{img_filename}_{str(i)}.png\")\n",
    "\n",
    "        # img_arr_augmented = resize_and_rescale(img_arr_augmented)\n",
    "        # np.save(f\"{OUTPUT_PATH}/{img_filename}_{str(i)}\", img_arr_augmented.numpy().astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/716 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'i' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mizunno/Projects/TBOI_item_detector/notebooks/3. data_augmentation.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m img_path \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(glob\u001b[39m.\u001b[39mglob(DATA_PATH \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     augment_image(img_path)\n",
      "\u001b[1;32m/home/mizunno/Projects/TBOI_item_detector/notebooks/3. data_augmentation.ipynb Cell 5\u001b[0m in \u001b[0;36maugment_image\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# img_arr_augmented = resize_and_rescale(img_arr_augmented)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# np.save(f\"{OUTPUT_PATH}/{img_filename}_{str(i)}\", img_arr_augmented.numpy().astype(np.float16))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# random_ops_combs = [random.sample(operations, k=random.randint(1,MAX_OPERATIONS_COMBINED)) for _ in range(N_RANDOM_OPERATIONS_COMBINATIONS)]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m random_ops_combs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, random_ops \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(random_ops_combs, start\u001b[39m=\u001b[39mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     img_arr_augmented \u001b[39m=\u001b[39m img_arr\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizunno/Projects/TBOI_item_detector/notebooks/3.%20data_augmentation.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m random_ops:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'i' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for img_path in tqdm.tqdm(glob.glob(DATA_PATH + \"*\")):\n",
    "    # augment_image(img_path)\n",
    "    no_agumentation(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "565bbc61ce0d5c839d8e0766ab268faab42aa5ba816b678f8400e1030c0d2b12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
